{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pdfplumber nltk pandas numpy openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUmhvAImYhT0",
        "outputId": "36a77316-0c06-4aea-8378-30fdd83b6194"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai pdfplumber pandas\n",
        "\n",
        "from pathlib import Path\n",
        "import pdfplumber, re, json, os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# ðŸ”‘ Load your OpenAI key correctly (secret name = \"sandra\")\n",
        "api_key = userdata.get(\"sandra\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "PDF_DIR = Path(\"/content/pdfs\")\n",
        "PDF_DIR.mkdir(exist_ok=True, parents=True)\n",
        "for p in Path(\"/content\").glob(\"*.pdf\"):\n",
        "    shutil.move(str(p), str(PDF_DIR / p.name))\n",
        "\n",
        "print(\"Now in /content/pdfs:\", [p.name for p in PDF_DIR.glob(\"*.pdf\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X32-zP9-YkRA",
        "outputId": "a732c99b-8dfd-4287-fd5e-9da0c5e226a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now in /content/pdfs: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Stage 2: Page-Aware Text Extraction (safer, no re-split) ===\n",
        "import re, pdfplumber\n",
        "from pathlib import Path\n",
        "\n",
        "def extract_clean_text_pages(pdf_path: Path):\n",
        "    \"\"\"\n",
        "    Return: list[(page_num:int, text:str)]\n",
        "    - Cleans hyphenated line breaks & excess newlines\n",
        "    - Drops Abstract only on the first few pages\n",
        "    - Stops at the first page that *starts with* a References/Bibliography heading\n",
        "    - No global join/re-split (so no content loss)\n",
        "    \"\"\"\n",
        "    pages = []\n",
        "    with pdfplumber.open(str(pdf_path)) as pdf:\n",
        "        for i, page in enumerate(pdf.pages, start=1):\n",
        "            t = page.extract_text() or \"\"\n",
        "            # de-hyphenate across line breaks\n",
        "            t = re.sub(r\"(\\w)-\\n(\\w)\", r\"\\1\\2\", t)\n",
        "            # normalize whitespace\n",
        "            t = re.sub(r\"[ \\t]+\", \" \", t)\n",
        "            t = re.sub(r\"\\n{2,}\", \"\\n\", t).strip()\n",
        "            pages.append((i, t))\n",
        "\n",
        "    # Remove Abstract only within the first 3 pages (if present)\n",
        "    for k in range(min(3, len(pages))):\n",
        "        pnum, txt = pages[k]\n",
        "        # remove a leading Abstract block conservatively\n",
        "        txt2 = re.sub(\n",
        "            r\"(?is)^\\s*abstract\\b.*?(?=\\n[A-Z][^\\n]{0,80}\\n|\\Z)\",  # up to next likely heading or end\n",
        "            \"\",\n",
        "            txt,\n",
        "            count=1\n",
        "        ).strip()\n",
        "        pages[k] = (pnum, txt2)\n",
        "\n",
        "    # Find the first page that LOOKS like a references page and stop there.\n",
        "    def is_refs_page(txt: str) -> bool:\n",
        "        # only count if heading near the top of the page\n",
        "        head = \"\\n\".join(txt.splitlines()[:20])\n",
        "        return bool(re.search(r\"(?im)^\\s*(references|bibliograph\\w*)\\s*$\", head))\n",
        "\n",
        "    stop_at = None\n",
        "    for idx, (pnum, txt) in enumerate(pages):\n",
        "        if is_refs_page(txt):\n",
        "            stop_at = idx\n",
        "            break\n",
        "    if stop_at is not None:\n",
        "        pages = pages[:stop_at]  # cut at the references page, keep original page splits\n",
        "\n",
        "    return pages"
      ],
      "metadata": {
        "id": "vOMFakj0Ysgs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect pages for each PDF (no merging)\n",
        "PDF_DIR = Path(\"/content/pdfs\")\n",
        "pdf_paths = sorted(PDF_DIR.glob(\"*.pdf\"))\n",
        "assert pdf_paths, f\"No PDFs found in {PDF_DIR}. Upload PDFs first.\"\n",
        "\n",
        "all_docs_pages = {}  # {pdf_name: [(page_num, text), ...]}\n",
        "for pdf_path in pdf_paths:\n",
        "    pages = extract_clean_text_pages(pdf_path)\n",
        "    all_docs_pages[pdf_path.name] = pages\n",
        "    print(f\"âœ… {pdf_path.name}: {len(pages)} pages kept (pre-LLM)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4FjMp126X5-",
        "outputId": "aa5ecd11-a70c-409b-9900-f04342ddba4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf: 78 pages kept (pre-LLM)\n",
            "âœ… 2008_MATABANE_FE3.pdf: 44 pages kept (pre-LLM)\n",
            "âœ… 2009_Bontle Nkuna_0605886P_Honours Report.pdf: 50 pages kept (pre-LLM)\n",
            "âœ… 2011_Peters_East Markoye_2011.pdf: 62 pages kept (pre-LLM)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Stage 3: Page-Referenced AI Extraction (per-PDF; stricter) ===\n",
        "from tqdm import tqdm\n",
        "import json, textwrap\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "schema = {\n",
        "  \"page_number\": \"integer\",\n",
        "  \"metadata\": {\n",
        "    \"title\": \"string\",\n",
        "    \"author\": \"string\",\n",
        "    \"year\": \"integer\",\n",
        "    \"supervisor\": \"string\",\n",
        "    \"institution\": \"string\",\n",
        "    \"location\": \"string\"\n",
        "  },\n",
        "  \"geology\": {\n",
        "    \"region\": \"string\",\n",
        "    \"formation\": \"string\",\n",
        "    \"rock_types\": [\"list of strings\"],\n",
        "    \"minerals\": [\"list of strings\"],\n",
        "    \"structures\": [\"list of strings\"],\n",
        "    \"tectonic_setting\": \"string\"\n",
        "  },\n",
        "  \"geochronology\": {\n",
        "    \"sample_id\": \"string\",\n",
        "    \"method\": \"string\",\n",
        "    \"age_Ma\": \"float\",\n",
        "    \"error_Ma\": \"float\",\n",
        "    \"rock_unit\": \"string\",\n",
        "    \"evidence\": \"string\"\n",
        "  },\n",
        "  \"geochemistry\": {\n",
        "    \"sample_id\": \"string\",\n",
        "    \"analyte\": \"string\",\n",
        "    \"value\": \"float\",\n",
        "    \"unit\": \"string\",\n",
        "    \"method\": \"string\",\n",
        "    \"context\": \"string\"\n",
        "  },\n",
        "  \"metallogeny\": {\n",
        "    \"mineralisation_type\": \"string\",\n",
        "    \"associated_structures\": [\"list of strings\"],\n",
        "    \"host_rocks\": [\"list of strings\"],\n",
        "    \"ore_minerals\": [\"list of strings\"],\n",
        "    \"alteration\": \"string\"\n",
        "  }\n",
        "}\n",
        "\n",
        "def ask_model(page_num: int, page_text: str, desc=\"Extracting\"):\n",
        "    # keep per-page cap; most pages are << 5500 chars anyway\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\":\n",
        "         \"You are a geology data extraction AI. Output valid JSON ONLY.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "Extract ONLY from the page text given. Obey this schema exactly:\n",
        "{json.dumps(schema, indent=2)}\n",
        "\n",
        "Rules:\n",
        "- Set \"page_number\": {page_num}.\n",
        "- Use ONLY facts present in the page text. Do NOT infer, guess, or use outside knowledge.\n",
        "- If a field is not present, set empty string (\"\"), 0, null, or [] as appropriate (NO 'Unknown').\n",
        "- If nothing relevant is present, return [] (empty list).\n",
        "- Keep lists deduplicated.\n",
        "\n",
        "PAGE TEXT (page {page_num}):\n",
        "{text[:5500]}\n",
        "\"\"\"}\n",
        "    ]\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        temperature=0.1,\n",
        "        max_tokens=1200,\n",
        "        response_format={\"type\": \"json_object\"}  # force JSON\n",
        "    )\n",
        "    raw = resp.choices[0].message.content.strip()\n",
        "    try:\n",
        "        data = json.loads(raw)\n",
        "    except Exception:\n",
        "        # try to salvage JSON object from code fences if present\n",
        "        raw2 = raw.strip(\"`\").replace(\"json\", \"\").strip()\n",
        "        data = json.loads(raw2)\n",
        "    return data\n",
        "\n",
        "# Run per PDF â†’ each gets its own extracted JSON\n",
        "OUT_DIR = Path(\"/content/extracted_json\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for pdf_name, page_list in all_docs_pages.items():\n",
        "    out_path = OUT_DIR / f\"{Path(pdf_name).stem}.extracted.json\"\n",
        "    records = []\n",
        "    for pnum, text in tqdm(page_list, desc=f\"Extracting {pdf_name}\", leave=False):\n",
        "        if not text:\n",
        "            continue\n",
        "        try:\n",
        "            rec = ask_model(pnum, text)\n",
        "            if rec:\n",
        "                records.append(rec)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ {pdf_name} p{pnum}: {e}\")\n",
        "\n",
        "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"âœ… Saved {len(records)} page records â†’ {out_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZE5eRj0xfk0",
        "outputId": "b329f8cf-d968-4224-87b9-a17806b8bfe5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved 78 page records â†’ /content/extracted_json/2007_Tshibubudze_THE MARKOYE FAULT_2007.extracted.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved 44 page records â†’ /content/extracted_json/2008_MATABANE_FE3.extracted.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved 50 page records â†’ /content/extracted_json/2009_Bontle Nkuna_0605886P_Honours Report.extracted.json\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved 62 page records â†’ /content/extracted_json/2011_Peters_East Markoye_2011.extracted.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                                                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved 186 page records â†’ /content/extracted_json/2021_Volcanic Architecture of the Hounde and Boromo Greenstone Belts_PhD_Thesis.extracted.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Stage 4: Reference-Aware Flatten (per-PDF + combined) ===\n",
        "from pathlib import Path\n",
        "import json, pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "IN_DIR  = Path(\"/content/extracted_json\")       # outputs of Stage 3\n",
        "OUT_DIR = Path(\"/content/flattened_csv\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def normalize_records(raw):\n",
        "    \"\"\"Stage-3 may store a list of dicts, or a dict per page. Normalize to list[dict].\"\"\"\n",
        "    if not raw:\n",
        "        return []\n",
        "    out = []\n",
        "    for item in raw:\n",
        "        if isinstance(item, list):\n",
        "            out.extend([x for x in item if isinstance(x, dict)])\n",
        "        elif isinstance(item, dict):\n",
        "            out.append(item)\n",
        "    return out\n",
        "\n",
        "def flatten_one_pdf(pdf_name: str, recs: list[dict]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Flatten per-PDF:\n",
        "      - de-dup (section, field, value) within this PDF\n",
        "      - union the page numbers where it appears\n",
        "    \"\"\"\n",
        "    combined = defaultdict(lambda: {\n",
        "        \"pdf_name\": pdf_name, \"section\": None, \"field\": None, \"value\": None, \"pages\": set()\n",
        "    })\n",
        "\n",
        "    for rec in recs:\n",
        "        page = rec.get(\"page_number\", None)\n",
        "        for section, fields in rec.items():\n",
        "            if section == \"page_number\":\n",
        "                continue\n",
        "\n",
        "            # section: metadata, geology, geochronology, geochemistry, metallogeny\n",
        "            if isinstance(fields, dict):\n",
        "                for k, v in fields.items():\n",
        "                    # keep zeros and False; skip only None or empty strings\n",
        "                    if v is None or (isinstance(v, str) and v.strip() == \"\"):\n",
        "                        continue\n",
        "                    if isinstance(v, list):\n",
        "                        for vv in v:\n",
        "                            if vv is None or (isinstance(vv, str) and vv.strip() == \"\"):\n",
        "                                continue\n",
        "                            key = (section, k, str(vv))\n",
        "                            node = combined[key]\n",
        "                            node[\"section\"] = section; node[\"field\"] = k; node[\"value\"] = vv\n",
        "                            if page is not None: node[\"pages\"].add(str(page))\n",
        "                    else:\n",
        "                        key = (section, k, str(v))\n",
        "                        node = combined[key]\n",
        "                        node[\"section\"] = section; node[\"field\"] = k; node[\"value\"] = v\n",
        "                        if page is not None: node[\"pages\"].add(str(page))\n",
        "\n",
        "            elif isinstance(fields, list):\n",
        "                for item in fields:\n",
        "                    if item is None or (isinstance(item, str) and item.strip() == \"\"):\n",
        "                        continue\n",
        "                    key = (section, \"list_item\", str(item))\n",
        "                    node = combined[key]\n",
        "                    node[\"section\"] = section; node[\"field\"] = \"list_item\"; node[\"value\"] = item\n",
        "                    if page is not None: node[\"pages\"].add(str(page))\n",
        "\n",
        "    flat = [{\n",
        "        \"pdf_name\": info[\"pdf_name\"],\n",
        "        \"section\": info[\"section\"],\n",
        "        \"field\": info[\"field\"],\n",
        "        \"value\": info[\"value\"],\n",
        "        \"pages\": \", \".join(sorted(info[\"pages\"])) if info[\"pages\"] else \"\"\n",
        "    } for info in combined.values()]\n",
        "\n",
        "    return pd.DataFrame(flat, columns=[\"pdf_name\",\"section\",\"field\",\"value\",\"pages\"])\n",
        "\n",
        "# ---- Run over all per-PDF JSONs from Stage 3 ----\n",
        "json_paths = sorted(IN_DIR.glob(\"*.extracted.json\"))\n",
        "assert json_paths, f\"No Stage-3 JSONs found in {IN_DIR}. Run Stage 3 first.\"\n",
        "\n",
        "dfs = []\n",
        "for jp in json_paths:\n",
        "    # derive a friendly pdf name (e.g., \"Thesis.extracted.json\" -> \"Thesis.pdf\")\n",
        "    pdf_name = jp.stem.replace(\".extracted\", \"\") + \".pdf\"\n",
        "    raw = json.loads(jp.read_text(encoding=\"utf-8\"))\n",
        "    recs = normalize_records(raw)\n",
        "    df   = flatten_one_pdf(pdf_name, recs)\n",
        "\n",
        "    out_csv = OUT_DIR / f\"{jp.stem}.flatten.csv\"\n",
        "    df.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"âœ“ {pdf_name}: {len(df)} rows â†’ {out_csv}\")\n",
        "    dfs.append(df)\n",
        "\n",
        "# combined CSV\n",
        "combined_df = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame(columns=[\"pdf_name\",\"section\",\"field\",\"value\",\"pages\"])\n",
        "combined_df.to_csv(OUT_DIR / \"_combined_flatten.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"\\nâœ… Combined flatten saved â†’ {OUT_DIR / '_combined_flatten.csv'}\")\n",
        "\n",
        "# quick peek\n",
        "combined_df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "US0jDjHu08G8",
        "outputId": "9cbc0c15-63f5-484a-f2e8-e8073674baf1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ 2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf: 417 rows â†’ /content/flattened_csv/2007_Tshibubudze_THE MARKOYE FAULT_2007.extracted.flatten.csv\n",
            "âœ“ 2008_MATABANE_FE3.pdf: 276 rows â†’ /content/flattened_csv/2008_MATABANE_FE3.extracted.flatten.csv\n",
            "âœ“ 2009_Bontle Nkuna_0605886P_Honours Report.pdf: 306 rows â†’ /content/flattened_csv/2009_Bontle Nkuna_0605886P_Honours Report.extracted.flatten.csv\n",
            "âœ“ 2011_Peters_East Markoye_2011.pdf: 278 rows â†’ /content/flattened_csv/2011_Peters_East Markoye_2011.extracted.flatten.csv\n",
            "âœ“ 2021_Volcanic Architecture of the Hounde and Boromo Greenstone Belts_PhD_Thesis.pdf: 798 rows â†’ /content/flattened_csv/2021_Volcanic Architecture of the Hounde and Boromo Greenstone Belts_PhD_Thesis.extracted.flatten.csv\n",
            "\n",
            "âœ… Combined flatten saved â†’ /content/flattened_csv/_combined_flatten.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      pdf_name        section        field  \\\n",
              "0  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf       metadata        title   \n",
              "1  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf       metadata       author   \n",
              "2  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf       metadata         year   \n",
              "3  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf       metadata   supervisor   \n",
              "4  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf       metadata  institution   \n",
              "5  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf       metadata     location   \n",
              "6  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf  geochronology       age_Ma   \n",
              "7  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf  geochronology     error_Ma   \n",
              "8  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf   geochemistry        value   \n",
              "9  2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf       metadata     location   \n",
              "\n",
              "                                               value  \\\n",
              "0  RELATIVE TIMING OF STRUCTURAL EVENTS: THE MARK...   \n",
              "1                                 ASINNE TSHIBUBUDZE   \n",
              "2                                               2007   \n",
              "3                                 Prof. Kim A.A Hein   \n",
              "4                    University of the Witwatersrand   \n",
              "5                         Johannesburg, South Africa   \n",
              "6                                                  0   \n",
              "7                                                  0   \n",
              "8                                                  0   \n",
              "9                                       Johannesburg   \n",
              "\n",
              "                                               pages  \n",
              "0                                                  1  \n",
              "1                                                  1  \n",
              "2                                               1, 2  \n",
              "3                                                  1  \n",
              "4                                               1, 2  \n",
              "5                                                  1  \n",
              "6  1, 11, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, ...  \n",
              "7  1, 10, 11, 13, 14, 15, 16, 17, 18, 19, 2, 20, ...  \n",
              "8  1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, ...  \n",
              "9                                                  2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-355e7bc3-c5b8-4de0-9536-05b014eb4aa3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>section</th>\n",
              "      <th>field</th>\n",
              "      <th>value</th>\n",
              "      <th>pages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>metadata</td>\n",
              "      <td>title</td>\n",
              "      <td>RELATIVE TIMING OF STRUCTURAL EVENTS: THE MARK...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>metadata</td>\n",
              "      <td>author</td>\n",
              "      <td>ASINNE TSHIBUBUDZE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>metadata</td>\n",
              "      <td>year</td>\n",
              "      <td>2007</td>\n",
              "      <td>1, 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>metadata</td>\n",
              "      <td>supervisor</td>\n",
              "      <td>Prof. Kim A.A Hein</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>metadata</td>\n",
              "      <td>institution</td>\n",
              "      <td>University of the Witwatersrand</td>\n",
              "      <td>1, 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>metadata</td>\n",
              "      <td>location</td>\n",
              "      <td>Johannesburg, South Africa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>geochronology</td>\n",
              "      <td>age_Ma</td>\n",
              "      <td>0</td>\n",
              "      <td>1, 11, 13, 14, 15, 16, 17, 18, 19, 2, 20, 21, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>geochronology</td>\n",
              "      <td>error_Ma</td>\n",
              "      <td>0</td>\n",
              "      <td>1, 10, 11, 13, 14, 15, 16, 17, 18, 19, 2, 20, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>geochemistry</td>\n",
              "      <td>value</td>\n",
              "      <td>0</td>\n",
              "      <td>1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf</td>\n",
              "      <td>metadata</td>\n",
              "      <td>location</td>\n",
              "      <td>Johannesburg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-355e7bc3-c5b8-4de0-9536-05b014eb4aa3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-355e7bc3-c5b8-4de0-9536-05b014eb4aa3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-355e7bc3-c5b8-4de0-9536-05b014eb4aa3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bfe10feb-5ec1-4930-8786-9f43828b6ff4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfe10feb-5ec1-4930-8786-9f43828b6ff4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bfe10feb-5ec1-4930-8786-9f43828b6ff4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 2075,\n  \"fields\": [\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2008_MATABANE_FE3.pdf\",\n          \"2021_Volcanic Architecture of the Hounde and Boromo Greenstone Belts_PhD_Thesis.pdf\",\n          \"2009_Bontle Nkuna_0605886P_Honours Report.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"geochronology\",\n          \"metallogeny\",\n          \"geochemistry\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"value\",\n          \"tectonic_setting\",\n          \"rock_types\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1576,\n        \"samples\": [\n          \"wavy to planar-bedded tuff lithofacies\",\n          \"Cleavage\",\n          \"subduction-related accretion of island arcs and mantle-plume accretion of oceanic plateaus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pages\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 611,\n        \"samples\": [\n          \"21, 29, 49, 50\",\n          \"23, 39\",\n          \"13, 15, 22, 34, 35, 50, 51, 54\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}