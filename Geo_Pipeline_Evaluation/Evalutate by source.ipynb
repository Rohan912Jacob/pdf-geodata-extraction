{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f701159-616d-4b41-b5dc-bdab8b91f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from charset_normalizer import from_path\n",
    "\n",
    "IN_DIR = Path(\".\")\n",
    "PATTERN = \"*.csv\"\n",
    "\n",
    "def read_csv_any(p: Path) -> pd.DataFrame:\n",
    "    enc = from_path(p).best().encoding or \"utf-8\"\n",
    "    df = pd.read_csv(p, encoding=enc, engine=\"python\")\n",
    "    df.columns = [str(c).strip().lstrip(\"\\ufeff\") for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def norm_decision(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.strip().str.lower()\n",
    "\n",
    "def compute_counts(df: pd.DataFrame) -> dict:\n",
    "    s = norm_decision(df[\"gold_decision\"])\n",
    "    c = (s == \"correct\").sum()\n",
    "    ic = (s == \"incorrect\").sum()\n",
    "    sk = (s == \"skip\").sum()\n",
    "    labeled = c + ic\n",
    "    all_rows = labeled + sk\n",
    "    acc = c / labeled if labeled else 0.0\n",
    "    acc_with_skip = c / all_rows if all_rows else 0.0\n",
    "    return dict(correct=int(c), incorrect=int(ic), skip=int(sk),\n",
    "                labeled=int(labeled), all_rows=int(all_rows),\n",
    "                accuracy=acc, accuracy_including_skip=acc_with_skip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e76fe5f-c45a-4312-a77d-12f4d6c1f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - Report\\Group_by_source\\accuracy_by_file.csv\n",
      " - Report\\Group_by_source\\accuracy_by_file_source.csv\n",
      " - Report\\Group_by_source\\accuracy_overall.csv\n",
      " - Report\\Group_by_source\\accuracy_overall_by_source.csv\n"
     ]
    }
   ],
   "source": [
    "files = sorted(IN_DIR.glob(PATTERN))\n",
    "if not files:\n",
    "    raise SystemExit(\"CSV file not found\")\n",
    "\n",
    "rows = []\n",
    "per_source_rows = []\n",
    "\n",
    "for f in files:\n",
    "    df = read_csv_any(f)\n",
    "    if \"gold_decision\" not in df.columns:\n",
    "        print(f\"[WARN] {f.name} has not gold_decision，Skipping now\")\n",
    "        continue\n",
    "    if \"source\" not in df.columns:\n",
    "        df[\"source\"] = \"\"  # If not, leave it blank as a group\n",
    "\n",
    "    # File-level aggregation\n",
    "    total_stats = compute_counts(df)\n",
    "    rows.append({\"file\": f.name, **total_stats})\n",
    "\n",
    "    # Group by source column（llm / rules / llm,rules / other）\n",
    "    df[\"source_norm\"] = df[\"source\"].astype(str).str.strip().str.lower()\n",
    "    for src_val, g in df.groupby(\"source_norm\", dropna=False):\n",
    "        stats = compute_counts(g)\n",
    "        per_source_rows.append({\n",
    "            \"file\": f.name,\n",
    "            \"source_group\": src_val or \"(empty)\",\n",
    "            **stats\n",
    "        })\n",
    "\n",
    "# Summary Table\n",
    "by_file = pd.DataFrame(rows).sort_values(\"file\")\n",
    "by_file_source = pd.DataFrame(per_source_rows).sort_values([\"file\",\"source_group\"])\n",
    "\n",
    "# Overall (all files combined)\n",
    "overall = compute_counts(pd.concat([read_csv_any(f) for f in files], ignore_index=True))\n",
    "overall_row = pd.DataFrame([{\"file\": \"TOTAL\", **overall}])\n",
    "\n",
    "# Overall by source\n",
    "all_df = pd.concat([read_csv_any(f) for f in files], ignore_index=True)\n",
    "if \"source\" not in all_df.columns:\n",
    "    all_df[\"source\"] = \"\"\n",
    "all_df[\"source_norm\"] = all_df[\"source\"].astype(str).str.strip().str.lower()\n",
    "overall_by_source = []\n",
    "for src_val, g in all_df.groupby(\"source_norm\", dropna=False):\n",
    "    overall_by_source.append({\n",
    "        \"source_group\": src_val or \"(empty)\",\n",
    "        **compute_counts(g)\n",
    "    })\n",
    "overall_by_source = pd.DataFrame(overall_by_source).sort_values(\"source_group\")\n",
    "\n",
    "# Output\n",
    "out_dir = Path(\"./Report/Group_by_source\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "by_file.to_csv(out_dir / \"accuracy_by_file.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "by_file_source.to_csv(out_dir / \"accuracy_by_file_source.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "overall_row.to_csv(out_dir / \"accuracy_overall.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "overall_by_source.to_csv(out_dir / \"accuracy_overall_by_source.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", out_dir / \"accuracy_by_file.csv\")\n",
    "print(\" -\", out_dir / \"accuracy_by_file_source.csv\")\n",
    "print(\" -\", out_dir / \"accuracy_overall.csv\")\n",
    "print(\" -\", out_dir / \"accuracy_overall_by_source.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3c093-4202-4949-979b-dd69cdc0e54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo-nlp)",
   "language": "python",
   "name": "geo-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
